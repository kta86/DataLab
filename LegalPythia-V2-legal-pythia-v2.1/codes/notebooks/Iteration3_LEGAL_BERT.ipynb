{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Iteration3_LEGAL_BERT.ipynb",
   "provenance": [
    {
     "file_id": "1cB4xNaET3XdKivMwl1Fl3ZTv8LV1fwCy",
     "timestamp": 1626963888581
    },
    {
     "file_id": "1jHFGvjOmJ4S4V9yyG0Hn-CIkpTIEuW_n",
     "timestamp": 1626958014715
    },
    {
     "file_id": "12sKT5Mp9j60QL1eNXB_D7TRksnaHeewh",
     "timestamp": 1626949067193
    },
    {
     "file_id": "1f4cKA6a3Eh1SXleZp8PAjHqdwg1tbYji",
     "timestamp": 1626782194048
    },
    {
     "file_id": "1PXu594OwWjxwcEcsAh-FYoG9lz-QdyPJ",
     "timestamp": 1626761807287
    },
    {
     "file_id": "1KQXHWSumyu4kqZx2NQijwlbIq80VPTWs",
     "timestamp": 1626173481795
    }
   ],
   "collapsed_sections": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "e740eede028741f38f7eab1a44166a7f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_f0e1d603d01e408ba75156c7422e2521",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_0e81b5ea40ac4e3b805c56ae5e6d6bd4",
       "IPY_MODEL_6ca5f7505bfa4b5db7b6b52356f8906a"
      ]
     }
    },
    "f0e1d603d01e408ba75156c7422e2521": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "0e81b5ea40ac4e3b805c56ae5e6d6bd4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_9cf4237381e84312a0744d0137b05bd0",
      "_dom_classes": [],
      "description": "Downloading: 100%",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 221792,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 221792,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_237a2df403094eeb925d000e485b6863"
     }
    },
    "6ca5f7505bfa4b5db7b6b52356f8906a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_1d31587bf4d64aee8426bfd01accb8da",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "â€‹",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 222k/222k [00:05&lt;00:00, 43.7kB/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_411645d29f334e9193394738d249a27f"
     }
    },
    "9cf4237381e84312a0744d0137b05bd0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "initial",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "237a2df403094eeb925d000e485b6863": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "1d31587bf4d64aee8426bfd01accb8da": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "411645d29f334e9193394738d249a27f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "fdb2a9f1968c4f438a268542c26b292f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_1f02f647b15c4beab0c2cc5db04bf1d5",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_706608dfd8a14e6987b119791b11944f",
       "IPY_MODEL_846698a872084b198decb8dc2e27c418"
      ]
     }
    },
    "1f02f647b15c4beab0c2cc5db04bf1d5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "706608dfd8a14e6987b119791b11944f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_94b35a86fa2b4b7493755e02ca1d8d6c",
      "_dom_classes": [],
      "description": "Downloading: 100%",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 989,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 989,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_fd842cbac36c47c7a45aa47bd16e64af"
     }
    },
    "846698a872084b198decb8dc2e27c418": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_11818713b59249dba2efdd7c7b62b729",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "â€‹",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 989/989 [00:00&lt;00:00, 5.90kB/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_2dadc2ee516c4cd4856012503be97625"
     }
    },
    "94b35a86fa2b4b7493755e02ca1d8d6c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "initial",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "fd842cbac36c47c7a45aa47bd16e64af": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "11818713b59249dba2efdd7c7b62b729": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "2dadc2ee516c4cd4856012503be97625": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "35d1198e3e8c47f897d8d387ef795dcd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_6092a0737ff646a3a0d75138f5b9b2d0",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_de04547a2cda431aad74ff9b4922a409",
       "IPY_MODEL_b9d0fc2a340145169081264c4f09c1af"
      ]
     }
    },
    "6092a0737ff646a3a0d75138f5b9b2d0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "de04547a2cda431aad74ff9b4922a409": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_82cb9858286c40449175be8c77cd2173",
      "_dom_classes": [],
      "description": "Downloading: 100%",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 141480422,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 141480422,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_dfd20b562d02466f8e2683fd0380b4ad"
     }
    },
    "b9d0fc2a340145169081264c4f09c1af": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_53d85b7044e847e4be3e70ba6344e5e9",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "â€‹",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 141M/141M [00:13&lt;00:00, 10.2MB/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_accad9b22aa342cf9eba512ef96b8974"
     }
    },
    "82cb9858286c40449175be8c77cd2173": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "initial",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "dfd20b562d02466f8e2683fd0380b4ad": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "53d85b7044e847e4be3e70ba6344e5e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "accad9b22aa342cf9eba512ef96b8974": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZiLkeyxXp1nQ"
   },
   "source": [
    "# **Iteration 3- LEGAL-BERT**\n",
    "## MSc Project \n",
    "## Surya L Ramesh (0206793)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kZUJuB-_pnAH",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1628708131733,
     "user_tz": -60,
     "elapsed": 10,
     "user": {
      "displayName": "Surya R",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjck1QrAr3OBVHDiFDEXm8F2D-3OgColYxFHK0CZXM=s64",
      "userId": "03485497232926795699"
     }
    },
    "outputId": "73812449-218a-4607-c02d-e7af0c6194ab"
   },
   "source": [
    "''' LEGAL-BERT - trained upto 20 epochs and best chosen'''\n",
    "    "
   ],
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "' LEGAL-BERT - trained upto 20 epochs and best chosen'"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IRgj-phNnfbH"
   },
   "source": [
    "## **Mount  google drive - will need authorisation**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "nvWU3oXz99Oh",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1628708160550,
     "user_tz": -60,
     "elapsed": 28822,
     "user": {
      "displayName": "Surya R",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjck1QrAr3OBVHDiFDEXm8F2D-3OgColYxFHK0CZXM=s64",
      "userId": "03485497232926795699"
     }
    },
    "outputId": "e831e847-62e3-430d-9945-d9ca8f297f02"
   },
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ],
   "execution_count": 2,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Input \u001B[1;32mIn [2]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgoogle\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcolab\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m drive\n\u001B[0;32m      2\u001B[0m drive\u001B[38;5;241m.\u001B[39mmount(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/content/drive/\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'google.colab'"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DcmhZTnAqcDN"
   },
   "source": [
    "## **Install required Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "BKiyCjAkE_Dz",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1628708169332,
     "user_tz": -60,
     "elapsed": 8788,
     "user": {
      "displayName": "Surya R",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjck1QrAr3OBVHDiFDEXm8F2D-3OgColYxFHK0CZXM=s64",
      "userId": "03485497232926795699"
     }
    },
    "outputId": "099820d1-00d7-497f-a4b9-c3932c49ae05"
   },
   "source": [
    "\n",
    "!pip install transformers\n",
    "!pip install sentencepiece"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "LaOXsbkdDXbn"
   },
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader, SequentialSampler, RandomSampler\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "from transformers import BertTokenizer  # modified\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import fnmatch\n",
    "from termcolor import colored\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import copy\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "from transformers import BertForSequenceClassification, AdamW\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W-pMvW1DnMZG"
   },
   "source": [
    "##**Check GPU and memory availability**\n",
    "   - code is from Google Colab official examples: https://colab.research.google.com/notebooks/pro.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uc2yAfOF012n",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1628708173539,
     "user_tz": -60,
     "elapsed": 28,
     "user": {
      "displayName": "Surya R",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjck1QrAr3OBVHDiFDEXm8F2D-3OgColYxFHK0CZXM=s64",
      "userId": "03485497232926795699"
     }
    },
    "outputId": "1e2eb034-d7db-4333-a003-e0770e462cad"
   },
   "source": [
    "# check GPU\n",
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
    "  print('and then re-execute this cell.')\n",
    "else:\n",
    "  print(gpu_info)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vlCRY19FZhq1",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1628708173540,
     "user_tz": -60,
     "elapsed": 17,
     "user": {
      "displayName": "Surya R",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjck1QrAr3OBVHDiFDEXm8F2D-3OgColYxFHK0CZXM=s64",
      "userId": "03485497232926795699"
     }
    },
    "outputId": "ae2d7948-d132-4981-bc5d-1e2e152dc97f"
   },
   "source": [
    "# check Memory \n",
    "\n",
    "from psutil import virtual_memory\n",
    "ram_gb = virtual_memory().total / 1e9\n",
    "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
    "\n",
    "if ram_gb < 20:\n",
    "  print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\n",
    "  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n",
    "  print('re-execute this cell.')\n",
    "else:\n",
    "  print('You are using a high-RAM runtime!')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "77FTH6A9DXbn",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1628708173979,
     "user_tz": -60,
     "elapsed": 14,
     "user": {
      "displayName": "Surya R",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjck1QrAr3OBVHDiFDEXm8F2D-3OgColYxFHK0CZXM=s64",
      "userId": "03485497232926795699"
     }
    },
    "outputId": "eea7d5e6-ff88-49c8-e51c-34e90bb39848"
   },
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "T3N2ghF_5MLJ"
   },
   "source": [
    ""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GeBbxqTuCrVm"
   },
   "source": [
    "## **Access datasets from the mounted Google Drive**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "C200b8aCDXbo"
   },
   "source": [
    "# Use Relative path \n",
    "#path = 'SNLI_Data_Csv'\n",
    "path = \"/content/drive/MyDrive/CleanedData_notEncoded\"\n",
    "modelPath = \"/content/drive/MyDrive/CleanedData_notEncoded/model_22_07_LegalBert\"\n",
    "dirList = os.listdir(path)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2YPhhnAo-NHO",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1628708173980,
     "user_tz": -60,
     "elapsed": 12,
     "user": {
      "displayName": "Surya R",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjck1QrAr3OBVHDiFDEXm8F2D-3OgColYxFHK0CZXM=s64",
      "userId": "03485497232926795699"
     }
    },
    "outputId": "5cd0c982-0a1a-4dab-ccd4-89fe25922e87"
   },
   "source": [
    "\n",
    "dirList"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rLeoMfJYnE7o"
   },
   "source": [
    "## **Load and view the previously cleaned dataset in Google Drive** \n",
    "-  after cleaning , only wanted columns are kept , remove'-' rows, from gold_label, remove rows with na , rename columns,"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A6_5u_M0DXbp",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1628708404324,
     "user_tz": -60,
     "elapsed": 648,
     "user": {
      "displayName": "Surya R",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjck1QrAr3OBVHDiFDEXm8F2D-3OgColYxFHK0CZXM=s64",
      "userId": "03485497232926795699"
     }
    },
    "outputId": "61e650ee-1755-4d90-9063-290abb14f06b"
   },
   "source": [
    "for dir in dirList:\n",
    "  sub_path = os.path.join(path,dir) \n",
    "  #print(sub_path)\n",
    "  if fnmatch.fnmatch(sub_path,'*_train*'):\n",
    "    print(colored('\\n In Filename and path: %s' % (sub_path),'blue')) \n",
    "    train_tidy = pd.read_csv(sub_path,nrows =350000)  # changed to 10K for experimentation \n",
    "    \n",
    "    \n",
    "  if fnmatch.fnmatch(sub_path,'*_val*'):  \n",
    "    print(colored('\\n In Filename and path: %s' % (sub_path),'blue')) \n",
    "    val_tidy = pd.read_csv(sub_path,nrows =10000) \n",
    "\n",
    "  if fnmatch.fnmatch(sub_path,'*df_test.csv*'):  \n",
    "    print(colored('\\n In Filename and path: %s' % (sub_path),'blue')) \n",
    "    test_tidy = pd.read_csv(sub_path,nrows =10000) "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 205
    },
    "id": "6ZU-XgsMWL4d",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1628708410130,
     "user_tz": -60,
     "elapsed": 792,
     "user": {
      "displayName": "Surya R",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjck1QrAr3OBVHDiFDEXm8F2D-3OgColYxFHK0CZXM=s64",
      "userId": "03485497232926795699"
     }
    },
    "outputId": "3b5c2317-befa-4950-be58-3a7224691eb5"
   },
   "source": [
    "test_tidy.head(5)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 205
    },
    "id": "K9_BxBdCDXbq",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1628708180192,
     "user_tz": -60,
     "elapsed": 17,
     "user": {
      "displayName": "Surya R",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjck1QrAr3OBVHDiFDEXm8F2D-3OgColYxFHK0CZXM=s64",
      "userId": "03485497232926795699"
     }
    },
    "outputId": "928fe520-0877-419d-a0b9-5281099094ba"
   },
   "source": [
    "train_tidy.head(5)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 205
    },
    "id": "d_SYUXD3odKa",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1628708180193,
     "user_tz": -60,
     "elapsed": 17,
     "user": {
      "displayName": "Surya R",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjck1QrAr3OBVHDiFDEXm8F2D-3OgColYxFHK0CZXM=s64",
      "userId": "03485497232926795699"
     }
    },
    "outputId": "0454a7a3-3bca-4d89-f94b-ddb7edd3cdf5"
   },
   "source": [
    "val_tidy.head(5)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2xAYpKvaDXbq"
   },
   "source": [
    ""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PgjTRWGboMaj"
   },
   "source": [
    "## **Define class for SNLIDataLegalBert**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SZjXcJ-7DXbr"
   },
   "source": [
    "''' initialising , data Loader (batches) ,encoding ,  Add [CLS] and [SEP] tokens, join the two sentences for the train and val datasets'''\n",
    "\n",
    "class SNLILegalBert(Dataset):\n",
    "\n",
    "  def __init__(self, train_df, val_df):\n",
    "    self.label_dict = {'entailment': 0, 'contradiction': 1, 'neutral': 2}\n",
    "\n",
    "    self.train_df = train_df\n",
    "    self.val_df = val_df\n",
    "\n",
    "    self.base_path = '/content/'\n",
    "    self.tokenizer = BertTokenizer.from_pretrained(\"nlpaueb/legal-bert-small-uncased\", do_lower_case=True) \n",
    "    self.train_data = None\n",
    "    self.val_data = None\n",
    "    self.init_data()\n",
    "\n",
    "  def init_data(self):\n",
    "    \n",
    "    self.train_data = self.load_data(self.train_df)\n",
    "    self.val_data = self.load_data(self.val_df)\n",
    "\n",
    "  def load_data(self, df):\n",
    "    MAX_LEN = 512   \n",
    "    token_ids = []\n",
    "    mask_ids = []\n",
    "    seg_ids = []\n",
    "    y = []\n",
    "\n",
    "    premise_list = df['premise'].to_list()\n",
    "    hypothesis_list = df['hypothesis'].to_list()\n",
    "    label_list = df['target'].to_list()\n",
    "\n",
    "    for (premise, hypothesis, label) in zip(premise_list, hypothesis_list, label_list):\n",
    "      premise_id = self.tokenizer.encode(premise, add_special_tokens = False)\n",
    "      hypothesis_id = self.tokenizer.encode(hypothesis, add_special_tokens = False)\n",
    "      pair_token_ids = [self.tokenizer.cls_token_id] + premise_id + [self.tokenizer.sep_token_id] + hypothesis_id + [self.tokenizer.sep_token_id]\n",
    "      premise_len = len(premise_id)\n",
    "      hypothesis_len = len(hypothesis_id)\n",
    "\n",
    "      segment_ids = torch.tensor([0] * (premise_len + 2) + [1] * (hypothesis_len + 1))  # sentence 0 and sentence 1\n",
    "      attention_mask_ids = torch.tensor([1] * (premise_len + hypothesis_len + 3))  # mask padded values\n",
    "\n",
    "      token_ids.append(torch.tensor(pair_token_ids))\n",
    "      seg_ids.append(segment_ids)\n",
    "      mask_ids.append(attention_mask_ids)\n",
    "      y.append(self.label_dict[label])\n",
    "    \n",
    "    token_ids = pad_sequence(token_ids, batch_first=True)\n",
    "    mask_ids = pad_sequence(mask_ids, batch_first=True)\n",
    "    seg_ids = pad_sequence(seg_ids, batch_first=True)\n",
    "    y = torch.tensor(y)\n",
    "    dataset = TensorDataset(token_ids, mask_ids, seg_ids, y)\n",
    "    print(len(dataset))\n",
    "    return dataset\n",
    "\n",
    "  def get_data_loaders(self, batch_size=32, shuffle=True):\n",
    "    train_loader = DataLoader(\n",
    "      self.train_data,\n",
    "      shuffle=shuffle,\n",
    "      batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "      self.val_data,\n",
    "      shuffle=shuffle,\n",
    "      batch_size=batch_size\n",
    "    )\n",
    "    return train_loader, val_loader"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "glIk27knBvb7"
   },
   "source": [
    "# convert columns of interest to string type"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "dvPby270B28T"
   },
   "source": [
    "train_tidy['premise'] = train_tidy['premise'].astype(str)\n",
    "train_tidy['hypothesis'] = train_tidy['hypothesis'].astype(str)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5sWbT1ZdB7Gw"
   },
   "source": [
    "val_tidy['premise'] = val_tidy['premise'].astype(str)\n",
    "val_tidy['hypothesis'] = val_tidy['hypothesis'].astype(str)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "v8qGN6BOXGS0"
   },
   "source": [
    "test_tidy['premise'] = test_tidy['premise'].astype(str)\n",
    "test_tidy['hypothesis'] = test_tidy['hypothesis'].astype(str)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oCZ2J7uUpG5S",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1628708422401,
     "user_tz": -60,
     "elapsed": 813,
     "user": {
      "displayName": "Surya R",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjck1QrAr3OBVHDiFDEXm8F2D-3OgColYxFHK0CZXM=s64",
      "userId": "03485497232926795699"
     }
    },
    "outputId": "6b8d8eda-eaf6-4c9e-81c3-bf82bae25d9d"
   },
   "source": [
    "test_tidy['premise']"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "x-p3kwsTB-HU"
   },
   "source": [
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "izU9B1WcXcLN"
   },
   "source": [
    "## **Setup for Training,Validating and Final Test**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c2ofX3mrq8kg"
   },
   "source": [
    "### **Define class for SNLIDataLegalBertPredictor- Used for the TestSet**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "73m6Yvg5kiWd"
   },
   "source": [
    "''' This class is for the Test set (prediction) to Initialize , data Loader (batches) ,\n",
    "encoding ,  Add [CLS] and [SEP] tokens, join the two sentences '''\n",
    "\n",
    "class SNLIBertPredictor(Dataset):\n",
    "\n",
    "  def __init__(self,input_df):\n",
    "    self.label_dict = {'entailment': 0, 'contradiction': 1, 'neutral': 2}\n",
    "\n",
    "    self.input_df = input_df\n",
    "\n",
    "    self.base_path = '/content/'\n",
    "\n",
    "    self.tokenizer = BertTokenizer.from_pretrained(\"nlpaueb/legal-bert-small-uncased\")\n",
    "    \n",
    "    self.input_data = None\n",
    "   # self.val_data = None\n",
    "    self.init_data()\n",
    "\n",
    "  def init_data(self):\n",
    "    \n",
    "    self.input_data = self.load_data(self.input_df)\n",
    "\n",
    "  def load_data(self, df):\n",
    "    MAX_LEN = 512   \n",
    "    token_ids = []\n",
    "    mask_ids = []\n",
    "    seg_ids = []\n",
    "    y = []\n",
    "\n",
    "    premise_list = df['premise'].to_list()\n",
    "    hypothesis_list = df['hypothesis'].to_list()\n",
    "    label_list = df['target'].to_list()\n",
    "\n",
    "    for (premise, hypothesis,label) in zip(premise_list, hypothesis_list,label_list):\n",
    "      premise_id = self.tokenizer.encode(premise, add_special_tokens = False)\n",
    "      hypothesis_id = self.tokenizer.encode(hypothesis, add_special_tokens = False)\n",
    "      pair_token_ids = [self.tokenizer.cls_token_id] + premise_id + [self.tokenizer.sep_token_id] + hypothesis_id + [self.tokenizer.sep_token_id]\n",
    "      premise_len = len(premise_id)\n",
    "      hypothesis_len = len(hypothesis_id)\n",
    "\n",
    "      segment_ids = torch.tensor([0] * (premise_len + 2) + [1] * (hypothesis_len + 1))  # sentence 0 and sentence 1\n",
    "      attention_mask_ids = torch.tensor([1] * (premise_len + hypothesis_len + 3))  # mask padded values\n",
    "\n",
    "      token_ids.append(torch.tensor(pair_token_ids))\n",
    "      seg_ids.append(segment_ids)\n",
    "      mask_ids.append(attention_mask_ids)\n",
    "      y.append(self.label_dict[label])\n",
    "    \n",
    "    token_ids = pad_sequence(token_ids, batch_first=True)\n",
    "    mask_ids = pad_sequence(mask_ids, batch_first=True)\n",
    "    seg_ids = pad_sequence(seg_ids, batch_first=True)\n",
    "    y = torch.tensor(y)\n",
    "    dataset = TensorDataset(token_ids, mask_ids, seg_ids,y)\n",
    "    print(len(dataset))\n",
    "    return dataset\n",
    "\n",
    "  def get_data_loaders(self, batch_size=32, shuffle=True):\n",
    "    input_loader = DataLoader(\n",
    "      self.input_data,\n",
    "      shuffle=shuffle,\n",
    "      batch_size=batch_size\n",
    "    )\n",
    "    return input_loader"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xeEQvnqHUX-m"
   },
   "source": [
    "### **Call SNLILegalBERT on the train and val dataset**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 154,
     "referenced_widgets": [
      "e740eede028741f38f7eab1a44166a7f",
      "f0e1d603d01e408ba75156c7422e2521",
      "0e81b5ea40ac4e3b805c56ae5e6d6bd4",
      "6ca5f7505bfa4b5db7b6b52356f8906a",
      "9cf4237381e84312a0744d0137b05bd0",
      "237a2df403094eeb925d000e485b6863",
      "1d31587bf4d64aee8426bfd01accb8da",
      "411645d29f334e9193394738d249a27f",
      "fdb2a9f1968c4f438a268542c26b292f",
      "1f02f647b15c4beab0c2cc5db04bf1d5",
      "706608dfd8a14e6987b119791b11944f",
      "846698a872084b198decb8dc2e27c418",
      "94b35a86fa2b4b7493755e02ca1d8d6c",
      "fd842cbac36c47c7a45aa47bd16e64af",
      "11818713b59249dba2efdd7c7b62b729",
      "2dadc2ee516c4cd4856012503be97625"
     ]
    },
    "id": "cc0Ky0ERDXbs",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1628708680444,
     "user_tz": -60,
     "elapsed": 249306,
     "user": {
      "displayName": "Surya R",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjck1QrAr3OBVHDiFDEXm8F2D-3OgColYxFHK0CZXM=s64",
      "userId": "03485497232926795699"
     }
    },
    "outputId": "e57cbcc8-13a9-41b8-ab82-1cdcb26134ed"
   },
   "source": [
    "\n",
    "snli_dataset = SNLILegalBert(train_tidy, val_tidy)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VSeRX2j9UpME"
   },
   "source": [
    "### **Load train and val dataset**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "UMcUuQv3DXbs"
   },
   "source": [
    "train_loader, val_loader = snli_dataset.get_data_loaders(batch_size=16)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "35d1198e3e8c47f897d8d387ef795dcd",
      "6092a0737ff646a3a0d75138f5b9b2d0",
      "de04547a2cda431aad74ff9b4922a409",
      "b9d0fc2a340145169081264c4f09c1af",
      "82cb9858286c40449175be8c77cd2173",
      "dfd20b562d02466f8e2683fd0380b4ad",
      "53d85b7044e847e4be3e70ba6344e5e9",
      "accad9b22aa342cf9eba512ef96b8974"
     ]
    },
    "id": "Q_iuEPoxtwvz",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1628708703119,
     "user_tz": -60,
     "elapsed": 22677,
     "user": {
      "displayName": "Surya R",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjck1QrAr3OBVHDiFDEXm8F2D-3OgColYxFHK0CZXM=s64",
      "userId": "03485497232926795699"
     }
    },
    "outputId": "272e48c1-0d59-41a3-da30-643e4d6772ee"
   },
   "source": [
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\"nlpaueb/legal-bert-small-uncased\",num_labels=3)\n",
    "model.to(device)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "oiq8irRRHYtR"
   },
   "source": [
    "from transformers import EarlyStoppingCallback"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "09FsSvVbH9FS"
   },
   "source": [
    "early stopping here, if time allows\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_-XR9qNcuR_v"
   },
   "source": [
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'gamma', 'beta']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.0}\n",
    "]"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "LutVR3M5uUAU"
   },
   "source": [
    "# This variable contains all of the hyperparemeter information our training loop needs\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=2e-5, correct_bias=False)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "90DT3W1gDXbu",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1628708703122,
     "user_tz": -60,
     "elapsed": 19,
     "user": {
      "displayName": "Surya R",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjck1QrAr3OBVHDiFDEXm8F2D-3OgColYxFHK0CZXM=s64",
      "userId": "03485497232926795699"
     }
    },
    "outputId": "705595c9-1e97-4591-c4b6-1062a320365b"
   },
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "k-eGhjaPDXbu"
   },
   "source": [
    "\n",
    "def multi_acc(y_pred, y_test):\n",
    "  acc = (torch.log_softmax(y_pred, dim=1).argmax(dim=1) == y_test).sum().float() / float(y_test.size(0))\n",
    "  return acc"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SbfbJ23S-M9y"
   },
   "source": [
    "# shutil - high-level operations on files\n",
    "\n",
    "import shutil"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "FyXiyi3BKE-9"
   },
   "source": [
    "# save model \n",
    "\n",
    "def save_checkpoint(state, is_best, epoch ):\n",
    "   path_to_model=modelPath + '/model_LegalBert_epoch{}.pt'.format( epoch+1)\n",
    "   torch.save(state, path_to_model)\n",
    "   print(\"The model has been saved in {}\".format(path_to_model))\n",
    "   if is_best:\n",
    "        shutil.copyfile(path_to_model, 'model_best.pth.tar')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "lidvh8H-DXbu"
   },
   "source": [
    "import time\n",
    "\n",
    "EPOCHS =1 # maximum no.of epochs to run \n",
    "\n",
    "def train(model, train_loader, val_loader, optimizer,epoch_to_resume):  \n",
    "  total_step = len(train_loader)\n",
    "  best_acc = 0\n",
    "  is_best = False\n",
    "\n",
    "  # check to resume from a previously saved epoch checkpoint\n",
    "\n",
    "  if (epoch_to_resume> 0 ):\n",
    "        path_to_model= modelPath +'/model_LegalBert_epoch{}.pt'.format( epoch_to_resume)\n",
    "        if os.path.isfile(path_to_model):\n",
    "            print(\"=> loading checkpoint '{}'\".format(path_to_model))\n",
    "            checkpoint = torch.load(path_to_model)\n",
    "            savd_epoch = checkpoint['epoch']\n",
    "            best_acc = checkpoint['best_acc']\n",
    "            model.load_state_dict(checkpoint['state_dict'])\n",
    "            optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "            print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                  .format(path_to_model, checkpoint['epoch']))\n",
    "        else:\n",
    "            print(\"=> no checkpoint found at '{}'\".format(path_to_model))\n",
    "\n",
    "  # training and validation for each epoch\n",
    "\n",
    "  for epoch in range(epoch_to_resume, EPOCHS):\n",
    "    start = time.time()\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    total_train_acc  = 0\n",
    "\n",
    "    # for each batch \n",
    "    for batch_idx, (pair_token_ids, mask_ids, seg_ids, y) in enumerate(train_loader):\n",
    "      optimizer.zero_grad()\n",
    "      pair_token_ids = pair_token_ids.to(device)\n",
    "      mask_ids = mask_ids.to(device)\n",
    "      seg_ids = seg_ids.to(device)\n",
    "      labels = y.to(device)\n",
    "      \n",
    "      loss, prediction = model(pair_token_ids, \n",
    "                             token_type_ids=seg_ids, \n",
    "                             attention_mask=mask_ids, \n",
    "                             labels=labels).values()\n",
    "\n",
    "      # loss = criterion(prediction, labels)\n",
    "      acc = multi_acc(prediction, labels)\n",
    "\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      \n",
    "      total_train_loss += loss.item()\n",
    "      total_train_acc  += acc.item()\n",
    "\n",
    "    # get average train accuracy and loss across all batches \n",
    "    train_acc  = total_train_acc/len(train_loader)\n",
    "    train_loss = total_train_loss/len(train_loader)\n",
    "    model.eval()\n",
    "    total_val_acc  = 0\n",
    "    total_val_loss = 0\n",
    "\n",
    "    \n",
    "   \n",
    "    with torch.no_grad():\n",
    "      for batch_idx, (pair_token_ids, mask_ids, seg_ids, y) in enumerate(val_loader):\n",
    "        optimizer.zero_grad()\n",
    "        pair_token_ids = pair_token_ids.to(device)\n",
    "        mask_ids = mask_ids.to(device)\n",
    "        seg_ids = seg_ids.to(device)\n",
    "        labels = y.to(device)\n",
    "\n",
    "        \n",
    "        # prediction = model(pair_token_ids, mask_ids, seg_ids)\n",
    "        loss, prediction = model(pair_token_ids, \n",
    "                             token_type_ids=seg_ids, \n",
    "                             attention_mask=mask_ids, \n",
    "                             labels=labels).values()\n",
    "        \n",
    "        # loss = criterion(prediction, labels)\n",
    "        acc = multi_acc(prediction, labels)\n",
    "\n",
    "        total_val_loss += loss.item()\n",
    "        total_val_acc  += acc.item()\n",
    "\n",
    "    val_acc  = total_val_acc/len(val_loader)\n",
    "    val_loss = total_val_loss/len(val_loader)\n",
    "    if(best_acc< val_acc):\n",
    "      best_acc = val_acc \n",
    "      is_best = True\n",
    "    else:\n",
    "      is_best = False\n",
    "    end = time.time()\n",
    "    hours, rem = divmod(end-start, 3600)\n",
    "    minutes, seconds = divmod(rem, 60)\n",
    "\n",
    "    print(f'Epoch {epoch+1}: train_loss: {train_loss:.4f} train_acc: {train_acc:.4f} | val_loss: {val_loss:.4f} val_acc: {val_acc:.4f}')\n",
    "    print(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))\n",
    "    \n",
    "    \n",
    "\n",
    "    # Saving the model\n",
    "    save_checkpoint({\n",
    "            'epoch': epoch + 1,\n",
    "            'best_acc': best_acc,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer' : optimizer.state_dict(),\n",
    "        }, is_best,epoch)\n",
    "   "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t0441gBjs7JM"
   },
   "source": [
    "## **Training with the trainset and validating with validation set**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "FGytjbRXDXbu",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1628708703126,
     "user_tz": -60,
     "elapsed": 17,
     "user": {
      "displayName": "Surya R",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjck1QrAr3OBVHDiFDEXm8F2D-3OgColYxFHK0CZXM=s64",
      "userId": "03485497232926795699"
     }
    },
    "outputId": "d8692ccb-6c44-4039-8be0-b3b9b391d00d"
   },
   "source": [
    "# commented out once epoch is chosen \n",
    "'''- this section is for training the model on trainset and validating on validation set'''\n",
    "\n",
    "#%% time \n",
    "#epoch_to_resume =6\n",
    "#train(model, train_loader, val_loader, optimizer,epoch_to_resume)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "wQoeURl1DXbv",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1628708703127,
     "user_tz": -60,
     "elapsed": 18,
     "user": {
      "displayName": "Surya R",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjck1QrAr3OBVHDiFDEXm8F2D-3OgColYxFHK0CZXM=s64",
      "userId": "03485497232926795699"
     }
    },
    "outputId": "972575bf-a3a4-4424-cd49-51bd66f3f403"
   },
   "source": [
    "print('Done')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7gAqWiB9rzvr"
   },
   "source": [
    "## **Testing chosen Epoch with TestSet**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7QApCsaX4Daf"
   },
   "source": [
    "'''- this section is for testing the chosen model on Testset'''\n",
    "\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "def test(model, test_loader, optimizer,epoch_to_use):  \n",
    "  # check to resume from a previously saved epoch checkpoint\n",
    "  if (epoch_to_use > 0 ):\n",
    "        path_to_model= modelPath +'/model_LegalBert_epoch{}.pt'.format( epoch_to_resume)\n",
    "        if os.path.isfile(path_to_model):\n",
    "            print(\"=> loading checkpoint '{}'\".format(path_to_model))\n",
    "            checkpoint = torch.load(path_to_model)\n",
    "            savd_epoch = checkpoint['epoch']\n",
    "            best_acc = checkpoint['best_acc']\n",
    "            model.load_state_dict(checkpoint['state_dict'])\n",
    "            optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "            print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                  .format(path_to_model, checkpoint['epoch']))\n",
    "        else:\n",
    "            print(\"=> no checkpoint found at '{}'\".format(path_to_model))\n",
    "            return; \n",
    "  y_pred_all = np.array([])\n",
    "  y_test_all = np.array([])\n",
    "  start = time.time() \n",
    "  total_test_loss = 0\n",
    "  total_test_acc  = 0\n",
    "\n",
    "  for batch_idx, (pair_token_ids, mask_ids, seg_ids, y) in enumerate(test_loader):\n",
    "      optimizer.zero_grad()\n",
    "      pair_token_ids = pair_token_ids.to(device)\n",
    "      mask_ids = mask_ids.to(device)\n",
    "      seg_ids = seg_ids.to(device)\n",
    "      labels = y.to(device)\n",
    "      \n",
    "      result = model(pair_token_ids, \n",
    "                            token_type_ids=seg_ids, \n",
    "                            attention_mask=mask_ids, \n",
    "                            labels=labels)\n",
    "      loss = result.loss\n",
    "      prediction = result.logits\n",
    "      if(torch.any(prediction.isnan())):\n",
    "        break;\n",
    "      \n",
    "      acc = multi_acc(prediction, labels)\n",
    "      #Add all predictions to y_pred_arr and all lables to y_test_arr\n",
    "      y_pred = torch.log_softmax(prediction, dim=1).argmax(dim=1)\n",
    "      y_pred_arr =  y_pred.to(\"cpu\").numpy().squeeze() \n",
    "      y_test_arr = labels.to(\"cpu\").numpy().squeeze()\n",
    "      y_pred_all = np.append(y_pred_all,y_pred_arr, axis=0)\n",
    "      y_test_all = np.append(y_test_all,y_test_arr, axis=0)  \n",
    "\n",
    "      total_test_loss += loss.item()\n",
    "      total_test_acc  += acc.item()\n",
    "\n",
    "      test_acc  = total_test_acc/len(test_loader)\n",
    "      test_loss = total_test_loss/len(test_loader)\n",
    "      end = time.time()\n",
    "      hours, rem = divmod(end-start, 3600)\n",
    "      minutes, seconds = divmod(rem, 60)\n",
    "\n",
    "  print(f'With Epoch {epoch_to_use}: test_loss: {test_loss:.4f} test_acc: {test_acc:.4f}')\n",
    "  print(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))\n",
    "  return y_pred_all,y_test_all \n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "lLsG5beB7rP9",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1628708715689,
     "user_tz": -60,
     "elapsed": 12577,
     "user": {
      "displayName": "Surya R",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjck1QrAr3OBVHDiFDEXm8F2D-3OgColYxFHK0CZXM=s64",
      "userId": "03485497232926795699"
     }
    },
    "outputId": "0a788301-b84f-4da3-b7e7-5f8c34a1a548"
   },
   "source": [
    "#Create object of SNLIAlberPredictor\n",
    "#GEt test dataloader\n",
    "snli_testset = SNLIBertPredictor(test_tidy)\n",
    "test_loader = snli_testset.get_data_loaders(batch_size=16)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zk0A4t5a7eey",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1628708731294,
     "user_tz": -60,
     "elapsed": 15620,
     "user": {
      "displayName": "Surya R",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjck1QrAr3OBVHDiFDEXm8F2D-3OgColYxFHK0CZXM=s64",
      "userId": "03485497232926795699"
     }
    },
    "outputId": "29b8824c-8497-4609-a849-7c619fde9458"
   },
   "source": [
    "\n",
    "epoch_to_resume =10 # chosen epoch based on training and val accuracy /loss chart \n",
    "\n",
    "y_pred_all,y_test_all = test(model, test_loader, optimizer,epoch_to_resume)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qVA1MOQf8xGn"
   },
   "source": [
    "## **Predict on Testset and Visualise Results**\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ZX6XNqn68xX-"
   },
   "source": [
    "# Libraries for this section \n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import itertools"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "WxLgn7qaX54a"
   },
   "source": [
    "''' function for custom confusion matrix in colour  '''\n",
    "\n",
    "def plot_confusion_matrix_custom(cm, classes, title='Confusion matrix - LEGAL-BERT ', cmap=plt.cm.Blues):\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes, rotation=45)\n",
    "\n",
    "    fmt =  'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    \n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.grid(False) \n",
    "   \n",
    "    plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "qqwEzbtqX8j-"
   },
   "source": [
    "''' function written to print classification report and display custom confusion matrix'''\n",
    "\n",
    "\n",
    "def visualize_confusion_matrix(y_pred_argmax, y_true):\n",
    "\n",
    "    classes = ['entailment','contradiction','neutral']\n",
    "    cm = confusion_matrix(y_true, y_pred_argmax)\n",
    "    con_mat_df = pd.DataFrame(cm)\n",
    "    \n",
    "    print(classification_report(y_pred_argmax, y_true,target_names=classes))\n",
    "\n",
    "    plot_confusion_matrix_custom(cm,classes)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zP10i2CyX9gX",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1628708731953,
     "user_tz": -60,
     "elapsed": 28,
     "user": {
      "displayName": "Surya R",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjck1QrAr3OBVHDiFDEXm8F2D-3OgColYxFHK0CZXM=s64",
      "userId": "03485497232926795699"
     }
    },
    "outputId": "ba4ab939-e911-4d7a-8a2a-3e9855b8656a"
   },
   "source": [
    "print(y_pred_all)\n",
    "print(y_test_all)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 521
    },
    "id": "kPtI7zyh9VFC",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1628708731961,
     "user_tz": -60,
     "elapsed": 32,
     "user": {
      "displayName": "Surya R",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjck1QrAr3OBVHDiFDEXm8F2D-3OgColYxFHK0CZXM=s64",
      "userId": "03485497232926795699"
     }
    },
    "outputId": "2a4e1e43-d4f0-4b03-ef26-5f490067f597"
   },
   "source": [
    "#classification report and Confusion matrix \n",
    "visualize_confusion_matrix(y_pred_all,y_test_all)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SbmgkZebtUrB"
   },
   "source": [
    "## -------------------------------    End of code for LEGAL BERT ------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cSGlk2TgAxeU"
   },
   "source": [
    "## Testing with Legal based sentences provided by company"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "1WukEBwpaZJy"
   },
   "source": [
    "# function to load data and tidy it \n",
    "# pass the dataframe, kepp only unwanted columns, remove'-' rows, from gold_label, remove rows with na , rename columns,lower case, replace all given special characters\n",
    "# diplay head()\n",
    "\n",
    "def data_load_tidy(dataframe): # remove isTest- not needed???\n",
    "    \n",
    "    dataframe = dataframe[['sentence1','sentence2','gold_label']]\n",
    "    \n",
    "    dataframe = dataframe[dataframe['gold_label'] != '-' ]\n",
    "    dataframe= dataframe.dropna(axis=0, inplace=False) # fixed additional nan in test and val with inplace=False \n",
    "    data_tidy = dataframe.rename(columns= {'sentence1':'premise', 'sentence2':'hypothesis', 'gold_label':'target'}, inplace=False)\n",
    "    #data_tidy['premise'] = data_tidy['premise'].astype(str)\n",
    "  \n",
    "    data_tidy['premise'] = data_tidy.premise.str.lower()\n",
    "    data_tidy['hypothesis'] = data_tidy.hypothesis.str.lower().str.replace('[^a-zA-Z ]' , '')    # lower, replace all  given special characters\n",
    "  \n",
    "    print(colored('\\n  data is tidied ....','green')) \n",
    "    return data_tidy\n",
    "\n",
    "    "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FmWinTqsURui",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1628708731961,
     "user_tz": -60,
     "elapsed": 27,
     "user": {
      "displayName": "Surya R",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjck1QrAr3OBVHDiFDEXm8F2D-3OgColYxFHK0CZXM=s64",
      "userId": "03485497232926795699"
     }
    },
    "outputId": "def59563-54b3-4f8a-e27b-0e6b22f17969"
   },
   "source": [
    "for dir in dirList:\n",
    "  sub_path = os.path.join(path,dir) \n",
    " \n",
    "  if fnmatch.fnmatch(sub_path,'*df_testlegal.csv*'):  \n",
    "    print(colored('\\n In Filename and path: %s' % (sub_path),'blue')) \n",
    "    df_legaltest = pd.read_csv(sub_path,nrows =20) \n",
    "    legaltest_tidy = data_load_tidy(df_legaltest)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "4CJSUnzbAvWU",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1628708731962,
     "user_tz": -60,
     "elapsed": 26,
     "user": {
      "displayName": "Surya R",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjck1QrAr3OBVHDiFDEXm8F2D-3OgColYxFHK0CZXM=s64",
      "userId": "03485497232926795699"
     }
    },
    "outputId": "93b7e15d-6c97-46c3-a61f-998592ad9390"
   },
   "source": [
    "legaltest_tidy.head(3)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "sp8QLBaDBKAK",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1628708731962,
     "user_tz": -60,
     "elapsed": 25,
     "user": {
      "displayName": "Surya R",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjck1QrAr3OBVHDiFDEXm8F2D-3OgColYxFHK0CZXM=s64",
      "userId": "03485497232926795699"
     }
    },
    "outputId": "a140a974-15fc-4ec7-c664-a64c6f822d57"
   },
   "source": [
    "legaltest_tidy.shape[0]"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "DzeLPdz0BNS7",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1628708939444,
     "user_tz": -60,
     "elapsed": 5952,
     "user": {
      "displayName": "Surya R",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjck1QrAr3OBVHDiFDEXm8F2D-3OgColYxFHK0CZXM=s64",
      "userId": "03485497232926795699"
     }
    },
    "outputId": "0099f73d-8071-478d-dbec-ebd84d3a12a1"
   },
   "source": [
    "#Create object of the legal predictor\n",
    "#get legaltest set\n",
    "snli_legaltestset = SNLIBertPredictor(legaltest_tidy)\n",
    "legaltest_loader = snli_legaltestset.get_data_loaders(batch_size=16)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "uZvB_aFXBOKr",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1628709305291,
     "user_tz": -60,
     "elapsed": 437,
     "user": {
      "displayName": "Surya R",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjck1QrAr3OBVHDiFDEXm8F2D-3OgColYxFHK0CZXM=s64",
      "userId": "03485497232926795699"
     }
    },
    "outputId": "a477b008-27b5-4664-827f-e9101fe924ff"
   },
   "source": [
    "# for LEGAL-BERT - testing on small Legalset\n",
    "\n",
    "epoch_to_resume = 10\n",
    "y_pred_legal,y_test_legal = test(model, legaltest_loader, optimizer,epoch_to_resume)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-cs-qj6KB8Ns"
   },
   "source": [
    "## Download colab notebook as HTML"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tkjh7f_JDgnV",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1628710097560,
     "user_tz": -60,
     "elapsed": 1337,
     "user": {
      "displayName": "Surya R",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjck1QrAr3OBVHDiFDEXm8F2D-3OgColYxFHK0CZXM=s64",
      "userId": "03485497232926795699"
     }
    },
    "outputId": "a12b917d-9246-4d7e-8738-d1133bb0d591"
   },
   "source": [
    "## download as html\n",
    "%%shell\n",
    "jupyter nbconvert --to html /content/Iteration3_LEGAL_BERT.ipynb"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}